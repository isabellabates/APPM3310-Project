{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06dd3056-392c-4158-ad58-539e88faf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of Taylor Swift lyrics using NMF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import decomposition\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ee075a2-30a1-454f-9b1b-6e6ed3cca0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from file\n",
    "tay = pd.read_csv('TaylorSwiftLyricsFeatureSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd146237-b6ee-4e53-a759-dbe5807b0cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_album</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>track_title</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>...</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_lyric</th>\n",
       "      <th>genres</th>\n",
       "      <th>year_released</th>\n",
       "      <th>world_sales_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.462</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425</td>\n",
       "      <td>76.009</td>\n",
       "      <td>232107</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:0Om9WAB5RS09L80DyOfTNa</td>\n",
       "      <td>0Om9WAB5RS09L80DyOfTNa</td>\n",
       "      <td>He said the way my blue eyes shined\\nPut those...</td>\n",
       "      <td>Country</td>\n",
       "      <td>2006</td>\n",
       "      <td>7000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Picture To Burn</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.877</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821</td>\n",
       "      <td>105.586</td>\n",
       "      <td>173067</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:32mVHdy0bi1XKgr0ajsBlG</td>\n",
       "      <td>32mVHdy0bi1XKgr0ajsBlG</td>\n",
       "      <td>State the obvious, I didn't get my perfect fan...</td>\n",
       "      <td>Country Rock</td>\n",
       "      <td>2006</td>\n",
       "      <td>7000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Teardrops On My Guitar</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.417</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.28800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289</td>\n",
       "      <td>99.953</td>\n",
       "      <td>203040</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:7zMcNqs55Mxer82bvZFkpg</td>\n",
       "      <td>7zMcNqs55Mxer82bvZFkpg</td>\n",
       "      <td>Drew looks at me\\nI fake a smile so he won't s...</td>\n",
       "      <td>Country Pop</td>\n",
       "      <td>2006</td>\n",
       "      <td>7000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>A Place In This World</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.777</td>\n",
       "      <td>9</td>\n",
       "      <td>-2.881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.05100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428</td>\n",
       "      <td>115.028</td>\n",
       "      <td>199200</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:73OX8GdpOeGzKC6OvGSbsv</td>\n",
       "      <td>73OX8GdpOeGzKC6OvGSbsv</td>\n",
       "      <td>I don't know what I want, so don't ask me\\nCau...</td>\n",
       "      <td>Country Pop</td>\n",
       "      <td>2006</td>\n",
       "      <td>7000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Cold as You</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.482</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.21700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261</td>\n",
       "      <td>175.558</td>\n",
       "      <td>239013</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:7an1exwMnfYRcdVQm0yDev</td>\n",
       "      <td>7an1exwMnfYRcdVQm0yDev</td>\n",
       "      <td>You have a way of coming easily to me\\nAnd whe...</td>\n",
       "      <td>Country</td>\n",
       "      <td>2006</td>\n",
       "      <td>7000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Lover</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Miss Americana &amp; the Heartbreak Prince</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.747</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.926</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487</td>\n",
       "      <td>150.088</td>\n",
       "      <td>234147</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:214nt20w5wOxJnY462klLw</td>\n",
       "      <td>214nt20w5wOxJnY462klLw</td>\n",
       "      <td>You know I adore you, I'm crazier for you\\nTha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>4000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Lover</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Paper Rings</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.719</td>\n",
       "      <td>9</td>\n",
       "      <td>-6.553</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>103.979</td>\n",
       "      <td>222400</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:4y5bvROuBDPr5fuwXbIBZR</td>\n",
       "      <td>4y5bvROuBDPr5fuwXbIBZR</td>\n",
       "      <td>The moon is high\\nLike your friends were the n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>4000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Lover</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Soon You'll Get Better (feat. Dixie Chicks)</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.566</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.90700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421</td>\n",
       "      <td>207.476</td>\n",
       "      <td>201587</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:4AYtqFyFbX0Xkc2wtcygTr</td>\n",
       "      <td>4AYtqFyFbX0Xkc2wtcygTr</td>\n",
       "      <td>The buttons of my coat were tangled in my hair...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>4000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Lover</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>The Archer</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.375</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166</td>\n",
       "      <td>124.344</td>\n",
       "      <td>211240</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:3pHkh7d0lzM2AldUtz2x37</td>\n",
       "      <td>3pHkh7d0lzM2AldUtz2x37</td>\n",
       "      <td>Combat\\nI'm ready for combat\\nI say I don't wa...</td>\n",
       "      <td>Dream Pop</td>\n",
       "      <td>2019</td>\n",
       "      <td>4000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Lover</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>You Need to Calm Down</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.671</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.00929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714</td>\n",
       "      <td>85.026</td>\n",
       "      <td>171360</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:6RRNNciQGZEXnqk8SQ9yv5</td>\n",
       "      <td>6RRNNciQGZEXnqk8SQ9yv5</td>\n",
       "      <td>You are somebody that I don't know\\nBut you're...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>2019</td>\n",
       "      <td>4000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      track_album  track_artist                                  track_title  \\\n",
       "0    Taylor Swift  Taylor Swift                                   Tim McGraw   \n",
       "1    Taylor Swift  Taylor Swift                              Picture To Burn   \n",
       "2    Taylor Swift  Taylor Swift                       Teardrops On My Guitar   \n",
       "3    Taylor Swift  Taylor Swift                        A Place In This World   \n",
       "4    Taylor Swift  Taylor Swift                                  Cold as You   \n",
       "..            ...           ...                                          ...   \n",
       "106         Lover  Taylor Swift       Miss Americana & the Heartbreak Prince   \n",
       "107         Lover  Taylor Swift                                  Paper Rings   \n",
       "108         Lover  Taylor Swift  Soon You'll Get Better (feat. Dixie Chicks)   \n",
       "109         Lover  Taylor Swift                                   The Archer   \n",
       "110         Lover  Taylor Swift                        You Need to Calm Down   \n",
       "\n",
       "     danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0           0.580   0.491    0    -6.462     1       0.0251       0.57500   \n",
       "1           0.658   0.877    7    -2.098     1       0.0323       0.17300   \n",
       "2           0.621   0.417   10    -6.941     1       0.0231       0.28800   \n",
       "3           0.576   0.777    9    -2.881     1       0.0324       0.05100   \n",
       "4           0.418   0.482    5    -5.769     1       0.0266       0.21700   \n",
       "..            ...     ...  ...       ...   ...          ...           ...   \n",
       "106         0.662   0.747   11    -6.926     0       0.0736       0.02800   \n",
       "107         0.811   0.719    9    -6.553     1       0.0497       0.01290   \n",
       "108         0.433   0.182    0   -12.566     1       0.0641       0.90700   \n",
       "109         0.292   0.574    0    -9.375     1       0.0401       0.12000   \n",
       "110         0.771   0.671    2    -5.617     1       0.0553       0.00929   \n",
       "\n",
       "     ...  valence    tempo  duration_ms  time_signature  \\\n",
       "0    ...    0.425   76.009       232107               4   \n",
       "1    ...    0.821  105.586       173067               4   \n",
       "2    ...    0.289   99.953       203040               4   \n",
       "3    ...    0.428  115.028       199200               4   \n",
       "4    ...    0.261  175.558       239013               4   \n",
       "..   ...      ...      ...          ...             ...   \n",
       "106  ...    0.487  150.088       234147               4   \n",
       "107  ...    0.865  103.979       222400               4   \n",
       "108  ...    0.421  207.476       201587               4   \n",
       "109  ...    0.166  124.344       211240               4   \n",
       "110  ...    0.714   85.026       171360               4   \n",
       "\n",
       "                                track_uri                track_id  \\\n",
       "0    spotify:track:0Om9WAB5RS09L80DyOfTNa  0Om9WAB5RS09L80DyOfTNa   \n",
       "1    spotify:track:32mVHdy0bi1XKgr0ajsBlG  32mVHdy0bi1XKgr0ajsBlG   \n",
       "2    spotify:track:7zMcNqs55Mxer82bvZFkpg  7zMcNqs55Mxer82bvZFkpg   \n",
       "3    spotify:track:73OX8GdpOeGzKC6OvGSbsv  73OX8GdpOeGzKC6OvGSbsv   \n",
       "4    spotify:track:7an1exwMnfYRcdVQm0yDev  7an1exwMnfYRcdVQm0yDev   \n",
       "..                                    ...                     ...   \n",
       "106  spotify:track:214nt20w5wOxJnY462klLw  214nt20w5wOxJnY462klLw   \n",
       "107  spotify:track:4y5bvROuBDPr5fuwXbIBZR  4y5bvROuBDPr5fuwXbIBZR   \n",
       "108  spotify:track:4AYtqFyFbX0Xkc2wtcygTr  4AYtqFyFbX0Xkc2wtcygTr   \n",
       "109  spotify:track:3pHkh7d0lzM2AldUtz2x37  3pHkh7d0lzM2AldUtz2x37   \n",
       "110  spotify:track:6RRNNciQGZEXnqk8SQ9yv5  6RRNNciQGZEXnqk8SQ9yv5   \n",
       "\n",
       "                                           track_lyric        genres  \\\n",
       "0    He said the way my blue eyes shined\\nPut those...       Country   \n",
       "1    State the obvious, I didn't get my perfect fan...  Country Rock   \n",
       "2    Drew looks at me\\nI fake a smile so he won't s...   Country Pop   \n",
       "3    I don't know what I want, so don't ask me\\nCau...   Country Pop   \n",
       "4    You have a way of coming easily to me\\nAnd whe...       Country   \n",
       "..                                                 ...           ...   \n",
       "106  You know I adore you, I'm crazier for you\\nTha...           NaN   \n",
       "107  The moon is high\\nLike your friends were the n...           NaN   \n",
       "108  The buttons of my coat were tangled in my hair...           NaN   \n",
       "109  Combat\\nI'm ready for combat\\nI say I don't wa...     Dream Pop   \n",
       "110  You are somebody that I don't know\\nBut you're...           Pop   \n",
       "\n",
       "    year_released world_sales_USD  \n",
       "0            2006         7000000  \n",
       "1            2006         7000000  \n",
       "2            2006         7000000  \n",
       "3            2006         7000000  \n",
       "4            2006         7000000  \n",
       "..            ...             ...  \n",
       "106          2019         4000000  \n",
       "107          2019         4000000  \n",
       "108          2019         4000000  \n",
       "109          2019         4000000  \n",
       "110          2019         4000000  \n",
       "\n",
       "[111 rows x 22 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tay['year_released'] = tay['track_album']\n",
    "tay['year_released'] = tay['year_released'].replace(['Taylor Swift', 'Fearless', 'Speak Now', 'Red', '1989',\n",
    "       'reputation', 'Lover'],[2006,2008,2010,2012,2014,2017,2019])\n",
    "tay['world_sales_USD'] = tay['track_album'].replace(['Taylor Swift', 'Fearless', 'Speak Now', 'Red', '1989',\n",
    "       'reputation', 'Lover'],[7000000,12000000,5500000,6000000,10500000,5000000,4000000])\n",
    "song_titles = tay['track_title'].values\n",
    "album = tay['track_album'].values\n",
    "tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0d12f67-5032-43c3-a57e-a90d452049b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      he said the way my blue eyes shined put those ...\n",
       "1      state the obvious  i didn t get my perfect fan...\n",
       "2      drew looks at me i fake a smile so he won t se...\n",
       "3      i don t know what i want  so don t ask me caus...\n",
       "4      you have a way of coming easily to me and when...\n",
       "                             ...                        \n",
       "106    you know i adore you  i m crazier for you than...\n",
       "107    the moon is high like your friends were the ni...\n",
       "108    the buttons of my coat were tangled in my hair...\n",
       "109    combat i m ready for combat i say i don t want...\n",
       "110    you are somebody that i don t know but you re ...\n",
       "Name: track_lyric, Length: 111, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data before applying NMF\n",
    "# remove \\n\n",
    "n = lambda x: re.sub('\\n',' ',x)\n",
    "alpha = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "# remove punctuation and make all lyrics lowercase\n",
    "lowercase = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "tay['track_lyric'] = tay.track_lyric.map(n).map(lowercase).map(alpha)\n",
    "\n",
    "# data after cleaning\n",
    "tay.track_lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b54156c3-d77b-4fa6-9d94-2c3888a993b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words that we don't want to include in analysis \n",
    "all_remove = ['just','don','gonna','cause','ll','ve','got','oh','eh','aah','want','way','away','ooh','wanna','ain','hey']\n",
    "remove = text.ENGLISH_STOP_WORDS.union(all_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bc6b57f-aa05-4fcc-91dc-4501998a28d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'before', 'of', 'moreover', 'whether', 'get', 'cannot', 'among', 'aah', 'below', 'so', 'although', 'whenever', 'or', 'made', 'hasnt', 'myself', 'former', 'who', 'less', 'his', 'ltd', 'eg', 'done', 'hereupon', 'front', 'thus', 'one', 'whereupon', 'them', 'our', 'none', 'forty', 'full', 'want', 'two', 'few', 'whatever', 'me', 'formerly', 'they', 'should', 'well', 'whole', 'the', 'move', 'sixty', 'most', 'still', 'serious', 'onto', 'itself', 'am', 'how', 'each', 'only', 'via', 'that', 'to', 'some', 'bill', 'enough', 'if', 'least', 'herself', 'anyhow', 'either', 'go', 'cant', 'from', 'since', 'been', 'other', 'might', 'by', 'everything', 'indeed', 'nobody', 'beforehand', 'about', 'these', 'take', 'nor', 'third', 'were', 'ie', 'de', 'once', 'everyone', 'wherein', 'anyone', 'around', 'side', 'us', 'when', 'becoming', 'yours', 'whence', 'someone', 'within', 'hereby', 'whereas', 'empty', 'six', 'ain', 'thereafter', 'bottom', 'therefore', 'more', 'will', 'further', 'him', 'name', 'both', 'down', 'therein', 'fifteen', 'sincere', 'hers', 'latterly', 'etc', 've', 'back', 'eleven', 'ever', 'somewhere', 'else', 'toward', 'may', 'yet', 'mine', 'during', 'inc', 'your', 'many', 'mostly', 'seeming', 'too', 'why', 'can', 'amoungst', 'not', 'co', 'three', 'twelve', 'hey', 'same', 'something', 'she', 'top', 'eight', 'nowhere', 'nine', 'have', 'there', 'besides', 'along', 'own', 'you', 'any', 'five', 'thin', 'its', 'see', 'latter', 'namely', 'sometime', 'anything', 'whom', 'away', 'll', 'others', 'way', 'hundred', 'con', 'hereafter', 'thick', 'being', 'rather', 'part', 'seems', 'across', 'elsewhere', 'per', 'do', 'perhaps', 'out', 'it', 'beyond', 'whither', 'find', 'whereafter', 'fill', 'which', 'through', 'a', 'what', 'due', 'would', 'upon', 'couldnt', 'my', 'every', 'even', 'such', 'almost', 'be', 'because', 'several', 'for', 'has', 'could', 'at', 'in', 're', 'yourselves', 'keep', 'with', 'thereby', 'he', 'then', 'eh', 'seemed', 'after', 'also', 'give', 'as', 'ours', 'an', 'neither', 'first', 'amount', 'on', 'above', 'their', 'next', 'i', 'and', 'here', 'describe', 'than', 'much', 'very', 'where', 'wanna', 'thence', 'must', 'always', 'hence', 'without', 'anywhere', 'sometimes', 'meanwhile', 'last', 'otherwise', 'those', 'alone', 'cry', 'no', 'please', 'seem', 'is', 'system', 'themselves', 'into', 'already', 'interest', 'become', 'mill', 'are', 'ourselves', 'another', 'this', 'however', 'somehow', 'himself', 'never', 'afterwards', 'between', 'whose', 'becomes', 'fifty', 'became', 'found', 'noone', 'four', 'all', 'don', 'herein', 'cause', 'put', 'we', 'thru', 'un', 'call', 'beside', 'under', 'up', 'over', 'while', 'nevertheless', 'her', 'just', 'now', 'show', 'wherever', 'ten', 'was', 'ooh', 'yourself', 'throughout', 'got', 'often', 'against', 'again', 'twenty', 'whereby', 'together', 'detail', 'everywhere', 'until', 'whoever', 'behind', 'amongst', 'fire', 'though', 'nothing', 'towards', 'except', 'off', 'thereupon', 'but', 'gonna', 'had', 'oh', 'anyway'}) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tfidf_v \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39mremove,min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m tfidf_freq \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_v\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_lyric\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2121\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2116\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2117\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2118\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2119\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2120\u001b[0m )\n\u001b[0;32m-> 2121\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1358\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable over raw text documents expected, string object received.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1356\u001b[0m     )\n\u001b[0;32m-> 1358\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_ngram_range()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_for_unused_params()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:570\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:97\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m constraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'before', 'of', 'moreover', 'whether', 'get', 'cannot', 'among', 'aah', 'below', 'so', 'although', 'whenever', 'or', 'made', 'hasnt', 'myself', 'former', 'who', 'less', 'his', 'ltd', 'eg', 'done', 'hereupon', 'front', 'thus', 'one', 'whereupon', 'them', 'our', 'none', 'forty', 'full', 'want', 'two', 'few', 'whatever', 'me', 'formerly', 'they', 'should', 'well', 'whole', 'the', 'move', 'sixty', 'most', 'still', 'serious', 'onto', 'itself', 'am', 'how', 'each', 'only', 'via', 'that', 'to', 'some', 'bill', 'enough', 'if', 'least', 'herself', 'anyhow', 'either', 'go', 'cant', 'from', 'since', 'been', 'other', 'might', 'by', 'everything', 'indeed', 'nobody', 'beforehand', 'about', 'these', 'take', 'nor', 'third', 'were', 'ie', 'de', 'once', 'everyone', 'wherein', 'anyone', 'around', 'side', 'us', 'when', 'becoming', 'yours', 'whence', 'someone', 'within', 'hereby', 'whereas', 'empty', 'six', 'ain', 'thereafter', 'bottom', 'therefore', 'more', 'will', 'further', 'him', 'name', 'both', 'down', 'therein', 'fifteen', 'sincere', 'hers', 'latterly', 'etc', 've', 'back', 'eleven', 'ever', 'somewhere', 'else', 'toward', 'may', 'yet', 'mine', 'during', 'inc', 'your', 'many', 'mostly', 'seeming', 'too', 'why', 'can', 'amoungst', 'not', 'co', 'three', 'twelve', 'hey', 'same', 'something', 'she', 'top', 'eight', 'nowhere', 'nine', 'have', 'there', 'besides', 'along', 'own', 'you', 'any', 'five', 'thin', 'its', 'see', 'latter', 'namely', 'sometime', 'anything', 'whom', 'away', 'll', 'others', 'way', 'hundred', 'con', 'hereafter', 'thick', 'being', 'rather', 'part', 'seems', 'across', 'elsewhere', 'per', 'do', 'perhaps', 'out', 'it', 'beyond', 'whither', 'find', 'whereafter', 'fill', 'which', 'through', 'a', 'what', 'due', 'would', 'upon', 'couldnt', 'my', 'every', 'even', 'such', 'almost', 'be', 'because', 'several', 'for', 'has', 'could', 'at', 'in', 're', 'yourselves', 'keep', 'with', 'thereby', 'he', 'then', 'eh', 'seemed', 'after', 'also', 'give', 'as', 'ours', 'an', 'neither', 'first', 'amount', 'on', 'above', 'their', 'next', 'i', 'and', 'here', 'describe', 'than', 'much', 'very', 'where', 'wanna', 'thence', 'must', 'always', 'hence', 'without', 'anywhere', 'sometimes', 'meanwhile', 'last', 'otherwise', 'those', 'alone', 'cry', 'no', 'please', 'seem', 'is', 'system', 'themselves', 'into', 'already', 'interest', 'become', 'mill', 'are', 'ourselves', 'another', 'this', 'however', 'somehow', 'himself', 'never', 'afterwards', 'between', 'whose', 'becomes', 'fifty', 'became', 'found', 'noone', 'four', 'all', 'don', 'herein', 'cause', 'put', 'we', 'thru', 'un', 'call', 'beside', 'under', 'up', 'over', 'while', 'nevertheless', 'her', 'just', 'now', 'show', 'wherever', 'ten', 'was', 'ooh', 'yourself', 'throughout', 'got', 'often', 'against', 'again', 'twenty', 'whereby', 'together', 'detail', 'everywhere', 'until', 'whoever', 'behind', 'amongst', 'fire', 'though', 'nothing', 'towards', 'except', 'off', 'thereupon', 'but', 'gonna', 'had', 'oh', 'anyway'}) instead."
     ]
    }
   ],
   "source": [
    "tfidf_v = TfidfVectorizer(stop_words=remove,min_df=0.1)\n",
    "tfidf_freq = tfidf_v.fit_transform(tay.track_lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f7d2e-deb3-4b0d-b429-355fb51ac3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer\n",
    "cv = TfidfVectorizer(stop_words='english',min_df=0.1,max_df=0.7)\n",
    "x = cv.fit_transform(tay.track_lyric).toarray()\n",
    "df = pd.DataFrame(x,columns=cv.get_feature_names())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039eb47-fe69-4088-b2bf-96b0a7cdc636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot of the eigenvalues of components\n",
    "lsa = TruncatedSVD(100)\n",
    "lsa.fit(df)\n",
    "lsa_features = lsa.transform(df)\n",
    "plt.figure()\n",
    "plt.plot(lsa.explained_variance_ratio_)\n",
    "xvals = np.linspace(0, 99)\n",
    "yvals = [0.025 for x in xvals]\n",
    "plt.plot(xvals,yvals)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.title('Scree Plot TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e5119-60d7-4b74-b3f8-36870b5b561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot of the eigenvalues of components\n",
    "lsa = TruncatedSVD(10)\n",
    "lsa.fit(df)\n",
    "lsa_features = lsa.transform(df)\n",
    "plt.figure()\n",
    "plt.plot(lsa.explained_variance_ratio_)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained ')\n",
    "plt.title('Scree Plot TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb612601-47ba-46de-87a2-18db3f4b0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a108e-856b-4054-98d7-ed8295cc98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply NMF\n",
    "def nmf_function(num_components, matrix, vectorizer):\n",
    "    nmf = NMF(num_components)\n",
    "    topic = nmf.fit_transform(matrix)\n",
    "    \n",
    "    index = []\n",
    "    for i in range(num_components):\n",
    "        index.append(i)\n",
    "    topic_word = pd.DataFrame(nmf.components_.round(3),\n",
    "             index = index,\n",
    "             columns = vectorizer.get_feature_names())\n",
    "    \n",
    "    print(print_topics(nmf, vectorizer.get_feature_names(), 15))\n",
    "    return topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d65ea0-9c62-42ed-bfba-9e6fccf5e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply NMF\n",
    "nmf_function(9,df,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72748c-bf19-4fa1-b019-a96a5e3eb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_function(9,tfidf_freq,tfidf_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b773159-5be0-40f9-9646-8ef6dcab0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels = ['Permanency, belonging','New things','Light, love',\n",
    "                'Trying, moving on','Staying, not moving on','Missing something, sad',\n",
    "                'Regret, remorse','New relationship','Contemplation, remembering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac2e0d-0c24-486a-a816-45c678945366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get H matrix\n",
    "def nmf_HMatrix(num_components, doc_text_matrix, vectorizer):\n",
    "    nmf = NMF(num_components)\n",
    "    doc_topic = nmf.fit_transform(doc_text_matrix)\n",
    "    \n",
    "    idx = []\n",
    "    for i in range(num_components):\n",
    "        idx.append(i) \n",
    "    H = pd.DataFrame(doc_topic.round(3),\n",
    "                    index = song_titles,\n",
    "                    columns = idx)\n",
    "    return H\n",
    "\n",
    "h9 = nmf_HMatrix(3,df,cv)\n",
    "h9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc7297-cf98-4132-b0f3-d2bda34bde52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity \n",
    "doc_similarity_matrix9 = pd.DataFrame(cosine_similarity(h9))\n",
    "doc_similarity_matrix9.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42584c9-346d-43a7-899b-81a57ac193da",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_similarity_matrix9[0].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaaeea3-1c61-4f7f-b159-e9432f2b304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tay.track_title[0],tay.track_title[83],tay.track_title[93],tay.track_title[58],tay.track_title[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7877b-67c8-487a-89da-2c4210b90a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_similarity_matrix9[13].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876af821-e171-4a60-a49a-86c3bb254ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tay.track_title[44],tay.track_title[55],tay.track_title[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d45bc3-442b-412c-b47e-1a987898828c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ef82f-ae80-4c07-a67a-e115e735bc22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f8090-313e-4a87-ae4c-ac62ec43a521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eaa3ae-518b-4e7c-8bbb-2c169494c3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a55b9b-2d0f-462d-82f9-cc378600a739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d3f5f-9180-48a9-8584-3ef4e3e4ef35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caadaea-f9e8-427b-b890-c96add1254ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k clustering on NMF (using TF-IDF)\n",
    "kmeans9 = KMeans(n_clusters=5,random_state=555)\n",
    "clustering_ori9 = kmeans9.fit_predict(h9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7312d-202d-4c23-9b29-91c238bcdcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans9.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77139cc-4266-4c78-a93d-f6e537ef764e",
   "metadata": {},
   "source": [
    "Clusters with Relation to Topics (based on cluster_centers_)\n",
    "Cluster 0: Mostly about Topic 3\n",
    "Cluster 1: Mostly about Topic 5\n",
    "Cluster 2: Mostly about Topics 2 and 4\n",
    "Cluster 3: Mostly about Topics 6, 8, 7, and 0\n",
    "Cluster 4: Mostly about Topic 1. Some Topic 5 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec38838-9986-4e5f-899c-a35c803aa21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulaizing clusters with TSNE\n",
    "dbscan9 = DBSCAN(eps=0.2,min_samples=3).fit(h9)\n",
    "Xtsne9 = TSNE(n_components=2,random_state=467).fit_transform(h9)\n",
    "dftsne9 = pd.DataFrame(Xtsne9)\n",
    "dftsne9['cluster'] = clustering_ori9\n",
    "dftsne9.columns = ['x1','x2','cluster']\n",
    "dftsne2d9 = dftsne9\n",
    "dftsne2d9['cluster'] = clustering_ori9\n",
    "\n",
    "tay_df = pd.concat([tay,dftsne2d9],axis=1)\n",
    "tay_df.to_csv(r'full_df2.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09556ae-248a-4a75-b851-96556d3145a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(data=dftsne2d9,x='x1',y='x2',hue='cluster',legend=\"full\",alpha=0.7)\n",
    "plt.title('Visualized on TSNE 9 topics')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
